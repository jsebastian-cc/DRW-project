{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":96164,"databundleVersionId":12993472,"sourceType":"competition"},{"sourceId":12462463,"sourceType":"datasetVersion","datasetId":7861436},{"sourceId":12477994,"sourceType":"datasetVersion","datasetId":7870836},{"sourceId":12492376,"sourceType":"datasetVersion","datasetId":7883469},{"sourceId":250907734,"sourceType":"kernelVersion"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom prophet import Prophet\nfrom sklearn.model_selection import TimeSeriesSplit\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Dispersion tolerance in *correct* function has been changed from 0.74 to 0.90","metadata":{}},{"cell_type":"code","source":"def iBlend(path_to_ds, file_short_names, sls):\n\n    def tida(sls):\n        \n        def read_subm(sls,i):\n            tnm = sls[\"subm\"][i][\"name\"]\n            # Check if this is the submission(47) file\n            if tnm == \"submission(47)\":\n                FiN = \"/kaggle/input/convergence-drw/\" + tnm + \".csv\"\n            else:\n                FiN = sls[\"path\"] + tnm + \".csv\"\n            return pd.read_csv(FiN).rename(columns={'target':tnm, sls[\"target\"]:tnm})\n        \n        dfs_subm = [read_subm(sls,i) for i in range(len(sls[\"subm\"]))]\n        df_subms = pd.merge(dfs_subm[0],  dfs_subm[1], on=['ID'])\n        \n        for i in range(2, len(sls[\"subm\"])): \n            df_subms = pd.merge(df_subms, dfs_subm[i], on=['ID'])\n            \n        cols = [col for col in df_subms.columns if col != \"ID\"]\n        short_name_cols = [c.replace(sls[\"prefix\"], '') for c in cols]\n        corrects  = [wt for wt in sls[\"subwts\"]]\n        weights   = [subm['weight'] for subm in sls[\"subm\"]]\n        corrects2 = [wt for wt in sls[\"subwts2\"]]\n        weights2  = [subm['weight'] for subm in sls[\"subm2\"]]\n        \n        def alls(x, cs=cols):\n            tes = {c: x[c] for c in cs}.items()\n            subms_sorted = [\n              t[0].replace(sls[\"prefix\"], '')\n              for t in sorted(tes,key=lambda k:k[1],reverse=True if sls[\"sort\"]=='desc' else False)]\n            return subms_sorted\n        \n        def correct(x, cs=cols, w=weights, cw=corrects, w2=weights2, cw2=corrects2):\n            ic = [x['alls'].index(c) for c in short_name_cols]\n            \n            if x['abs(mx-m)'] > 0.80:\n                cS = [x[cols[j]] * (w [j] + cw [ic[j]]) for j in range(len(cols))]\n            else:\n                cS = [x[cols[j]] * (w2[j] + cw2[ic[j]]) for j in range(len(cols))]\n            return sum(cS)\n\n        def amxm(x, cs=cols):\n            list_values = x[cs].to_list()\n            mxm = abs(max(list_values)-min(list_values))\n            return mxm\n\n        df_subms['abs(mx-m)']   = df_subms.apply(lambda x: amxm   (x), axis=1)\n        df_subms['row_mean'] = df_subms[cols].mean(axis=1)\n        df_subms['row_std']  = df_subms[cols].std(axis=1)\n        df_subms['alls']        = df_subms.apply(lambda x: alls   (x), axis=1)\n        df_subms[sls[\"target\"]] = df_subms.apply(lambda x: correct(x), axis=1)\n        \n        schema_rename = { old_nc:new_shnc for old_nc, new_shnc in zip(cols, short_name_cols) }\n        \n        df_subms = df_subms.rename(columns=schema_rename)\n        df_subms = df_subms.rename(columns={sls[\"target\"]:\"ensemble\"})\n        \n        df_subms.insert(loc=1, column=' _ ', value=['   '] * sls[\"q_rows\"])\n        \n        df_subms[' _ '] = df_subms[' _ '].astype(str)\n        pd.set_option('display.max_rows',100)\n        pd.set_option('display.float_format', '{:.3f}'.format)\n        vcols = ['ID'] + [' _ '] + short_name_cols + [' _ '] + ['abs(mx-m)'] + [' _ '] + ['alls'] + [' _ '] + ['ensemble']\n        df_subms = df_subms[vcols]\n        display(df_subms.head(100))\n        pd.set_option('display.float_format', '{:.7f}'.format)\n        df_subms = df_subms.rename(columns={\"ensemble\":sls[\"target\"]})\n        \n        return df_subms\n        \n    sample_subm = pd.read_csv(path_to_ds + file_short_names[1] + \".csv\")\n    \n    def ensemble_tida(sls,submission=sample_subm):   \n        sls['sort'] = 'desc'\n        dfs = tida(sls)\n        dfD = dfs[['ID', sls['target']]]\n        dfD.to_csv(f'tida_desc.csv', index=False)\n        sls['sort'] = 'asc'\n        dfs = tida(sls)\n        dfA = dfs[['ID', sls['target']]]\n        dfA.to_csv(f'tida_asc.csv',  index=False)\n        target,d,a = sls['target'],sls['desc'],sls['asc']\n        submission[target] = dfD[target] * d + a * dfA[target]\n        return submission\n\n    submission = ensemble_tida(sls)\n    \n    return submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T08:31:26.848679Z","iopub.execute_input":"2025-07-16T08:31:26.849368Z","iopub.status.idle":"2025-07-16T08:31:27.274583Z","shell.execute_reply.started":"2025-07-16T08:31:26.849343Z","shell.execute_reply":"2025-07-16T08:31:27.27348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_prophet_enhancement(df_ensemble, prophet_weight=0.01):\n    \"\"\"\n    Train a Prophet model on the ensemble predictions and blend with small weight\n    Parameters:\n    df_ensemble: DataFrame with ID and prediction columns\n    prophet_weight: Weight for Prophet predictions (default 0.01)\n    \"\"\"\n    print(\"Training Prophet model for ensemble enhancement...\")\n    # Prepare data for Prophet\n    # Use a more recent base date and scale IDs to fit within reasonable date range\n    prophet_df = pd.DataFrame()\n    # Scale IDs to hours instead of days to avoid overflow\n    base_date = pd.to_datetime('2024-01-01')\n    # Convert IDs to hours (538150 hours â‰ˆ 61 years, which is manageable)\n    prophet_df['ds'] = base_date + pd.to_timedelta(df_ensemble['ID'] - 1, unit='H')\n    prophet_df['y'] = df_ensemble['prediction']\n    # Advanced Prophet configuration with tuned hyperparameters\n    model = Prophet(\n        # Growth parameters\n        growth='linear',\n        changepoint_prior_scale=0.06,  # More flexible trend changes\n        changepoint_range=0.9,         # Allow changepoints through 90% of data\n        n_changepoints=75,             # More changepoints for complex patterns\n        \n        # Seasonality parameters\n        yearly_seasonality=True, weekly_seasonality=True,\n        daily_seasonality=False, seasonality_mode='multiplicative',  # Better for varying amplitude\n        seasonality_prior_scale=10.0,      # Strong seasonality\n        \n        # Holiday effects (can add specific holidays if known)\n        holidays_prior_scale=10.0,\n        # Uncertainty intervals\n        interval_width=0.95, uncertainty_samples=1000,\n        # MCMC sampling for better uncertainty estimates\n        mcmc_samples=0,  # Set to 300 for full Bayesian inference (slower)\n    )\n    # Add custom seasonalities for potential patterns\n    # Adjust periods to work with hourly data\n    model.add_seasonality( name='pattern_730h',  # ~30 days in hours\n                           period=730, fourier_order=5, prior_scale=10)\n    \n    model.add_seasonality( name='pattern_2190h',  # ~3 months in hours\n                           period=2190, fourier_order=10, prior_scale=5)\n    \n    # Add regressors if we have additional features from the ensemble\n    # For example, we could use the variance or ranking information\n    if 'abs(mx-m)' in df_ensemble.columns:\n        prophet_df['variance'] = df_ensemble['abs(mx-m)']\n        prophet_df['row_mean']   = df_ensemble['row_mean']\n        prophet_df['row_std']    = df_ensemble['row_std']\n\n        model.add_regressor('variance', prior_scale=5.0)\n        model.add_regressor('row_mean', prior_scale=3.0)\n        model.add_regressor('row_std',  prior_scale=3.0)\n    # Fit the model\n    print(\"Fitting Prophet model...\")\n    model.fit(prophet_df)\n    \n    # Make predictions\n    future = prophet_df[['ds']].copy()  # Use the same dataframe for predictions\n    if 'variance' in prophet_df.columns:\n        future['variance'] = prophet_df['variance']\n        future['row_mean'] = prophet_df['row_mean']\n        future['row_std']  = prophet_df['row_std']\n    \n    forecast = model.predict(future)\n    # Extract predictions\n    prophet_predictions = forecast['yhat'].values\n    \n    # Blend with ensemble\n    ensemble_predictions = df_ensemble['prediction'].values\n    final_predictions = (1 - prophet_weight) * ensemble_predictions + prophet_weight * prophet_predictions\n    # Create final dataframe\n    \n    df_final = pd.DataFrame({'ID': df_ensemble['ID'], 'prediction': final_predictions})  \n    # Print enhancement statistics\n    print(f\"\\nProphet Enhancement Statistics:\")\n    print(f\"Mean adjustment: {np.mean(prophet_predictions - ensemble_predictions):.6f}\")\n    print(f\"Std adjustment: {np.std(prophet_predictions - ensemble_predictions):.6f}\")\n    print(f\"Max adjustment: {np.max(np.abs(prophet_predictions - ensemble_predictions)):.6f}\")\n    # Plot components if needed (commented out for production)\n    # model.plot_components(forecast)\n    \n    return df_final, model, forecast","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Main execution\npath_to_ds ='/kaggle/input/15-juli-2025-drw/submission '\nfile_short_names = ['0.83975','0.86767','0.88377','0.89178','submission(47)']\n\nparams = { 'path'  : path_to_ds, 'sort'  : \"dynamic\", 'target': \"prediction\", \n           'q_rows': 538_150, 'prefix': \"subm_\", 'desc': 0.30, 'asc' : 0.70, \n           'subwts': [+0.20, +0.10, -0.05,-0.10,-0.15],\n           'subm'  : [ { 'name':file_short_names[0],'weight':0.20, },\n                       { 'name':file_short_names[1],'weight':0.20, },\n                       { 'name':file_short_names[2],'weight':0.21, },\n                       { 'name':file_short_names[3],'weight':0.22, },\n                       { 'name':file_short_names[4],'weight':0.30, }],\n           'subwts2': [+0.18, +0.09, -0.04,-0.09,-0.14],\n           'subm2'  : [{ 'name':file_short_names[0],'weight':0.19, },\n                       { 'name':file_short_names[1],'weight':0.20, },\n                       { 'name':file_short_names[2],'weight':0.21, },\n                       { 'name':file_short_names[3],'weight':0.22, },\n                       { 'name':file_short_names[4],'weight':0.3, }]}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Create ensemble predictions\ndf_ensemble = iBlend(path_to_ds, file_short_names, params)\n\n# Step 2: Apply Prophet enhancement\ndf_final, prophet_model, forecast = train_prophet_enhancement(df_ensemble, prophet_weight=0.085)\n\n# Step 3: Save final predictions\ndf_final.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nFinal submission saved to 'submission.csv'\")\nprint(f\"Shape: {df_final.shape}\")\nprint(f\"Prediction range: [{df_final['prediction'].min():.6f}, {df_final['prediction'].max():.6f}]\")\n\n# Display sample predictions\ndisplay(df_final.head(20))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}